Immediatly:

10. !!!!! IMPORTANT !!!! Figure out how to reconcile candidates always uping the term with healing
                         back to an older term. Must have misread something in the raft doc.
			 build tests for it and make em work. Need PreVote and CheckQuorum.

			 https://dev.to/tarantool/raft-notalmighty-how-to-make-it-more-robust-3a11

20. Leader needs to treat command response as ok only if no error is present.

22. Leader is supposed to save record before sending. That enables retry, I guess.
    so I need to code for that. So leader's lastLogIndex will be greater than
    everyone else's if no messages went out. That means when a leader is elected
    it needs to check its last log entry, and if it was not committed (no response
    data saved) then it does the broadcast command process. Maybe store pending
    command in a separate table and delete/insert on completion? Make logAPI
    support completion operation regardless, as different than a re-write operation.

    !!!! Paper has implications about multiple uncommitted recors in flight at the
    same time. See figure 7. I don't see how that makes sense unless the followers
    maintain a queue of unprocessed updates. If I don't support this, how bad is it?
    The complexity of uncommitted records at leader and at follower and of 

    !!! Clean up LogRec, chaning "user_data" to command and result and add custom json serializer so
        that serialising the entries array just works

    !!! Change all the references to myPrevLogTerm etc, should be looking at
        the log data in the message to see what was sent. this is a reply problem at
	leader, needs to understant what the reply means. Should be either hearbeat (no entries)
	or it should be determinable from the log records orignally sent. 
	
    When the responses
    come back (read paper carefully, do we need num_server/2 and count ourselves,
    or num_server/2 +1 because paper says majority?) then process it locally
    and update the log record. This argues that leader code for pending command
    needs to change to be based on the logLastIndex getting updated, maybe. Anyway
    another refactor for sure. Maybe self.append_command_record call? Then it
    can trigger any waiting pilot call?

23. See if message base_class has any value. Also study change to dataclasses

25. Add "caller_context" to command ops, pass it on process_command and return it
    in result. Maybe try one more time to make apply_command cleaner (and rename it
    while we are at it).
    

30. Need to add follower overwrite superceeded code, if leader says write this at
   this location, follower needs to delete old record. Prolly want a callack to
   pilot to tell them about it. Non-idempotent code needs to figure out how to
   undo deleted ops, or else throw an error. So prolly we want an error callback
   in pilot for when we can't provide sync, and also have an "undo" function in
   pilot. So we call "undo" then if it fails or doesn't exist we send out a new
   message type FOLLOWER_CANNOT_SYNC. Also need to have a callback in pilot for
   receipt of this. If we build a cluster class it should probably be able
   to save to records in conflict and disable the server. Maybe the server should
   disable itself?

31. Update hull api, __init__ should not be in it, so some sort of set_config
    thing. Think about updating config while running. Maybe have some sort
    of feature in hull that holds any messages while reconfig runs?

33. Move log_api to api module

41. rough out ideas for cluster class
    1. Knows about "static config" provided at startup. Can be programatically changed?
    2. Knows about "dynamic config" resulting from cluster changes while running.
    3. teach candidate and leader to use it
    4. build quorum feature such that (if configed) there is a minimum dynamic cluster
       size for starting election, with default of 1/2 + 1 of static config. Prove this
       prevents the inconsistent values at same log index problem after partition heal


PNEN
6. Think deep about reporting errors in raft code, and detecting them in testing. Break something
   such as rejected append entries and fiddle. Maybe can use substate stuff to alert to error
   and give pilot an api entry on hull to call to get errors?


9. Think about providing an optional uri map implementation for users.

11. Figure out how to log config changes, and in the process make general mechanism for
    non-command records.

20, Change log api to support multiple record types, command, cluster_config, for sure maybe others.

21. Change command processor sequence to provide unsaved log record with message then save the result.
   Check raft.pdf to see if there is an implication that a restarted leader might have uncommitted
   records to apply, and if not then get rid of whole committed/not committed logic everywhere. Otherwise
   think about how to store them, maybe separate table so that there is no confusion about what the
   log actually looks like?


30. Add config read and write and config-to-and-from-json to hull. Think about defining
    and API for the hull (probably not since it needs stuff at init)

DONE!!!!!!7. !!!!! IMPORTANT !!!! change log api to be async

DONE! 8. fiddle with test logging to make it more helpful. different loggers for things, for example
       

DONE! 1. Messaege classes update
   a. Also remove leaderCommit from vote.
   b. Consider removing the data stuff from the messages too, it is not requred except for
      append entries sequences
   c. Look at each one for simplifications and clarifications. Build short and long __rep__
      for each

DONE! 2. Condense comms and DSL into a single structure, something like "pilot".

DONE 3. Make command call part of base state with appropriate response if not leader. Follower replies
   "redirect: uri", candiate response "retry". Build a test sequence for this.

DONE! 4. Build test wrapper (maybe an implementation of "pilot"?) that supports
   a. message pausing based on patterns, e.g. after sending an apppend entries response. DONE!
   b. Have it also know how to perform simulated timer triggers
      1. Figure out a clean way to manage call_later tasks from base state or from hull
         so that code looks sensible but supports manipulation during testing.
   c. Add support for firing breakpoint in on_message when condition met. Maybe subclass
      hull? Maybe monkey patch it? DONE!

DONE! 4W. Pull message transport code into simnet class, teach it to simulate partions.
    a. Keep granular api in current server and cluster that allows individual messages
       and the deliver_all_pending functions, along with the condition variable stuff


DONE! 5. Need timeout mechanism for command (timeout supplied to condition.wait)

   
DONE 6. fix the asyncio fixture setting problem in tests, have to update the re-election tests


