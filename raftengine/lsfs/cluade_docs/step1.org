
Using overview.org as a project guide and development_plan.org as
a process guide:

Build a simple version of the Record Stream Files concept.

1. Create a test dictionary with five key value pairs where the key is a random
   lowercase letter and the value is a random integer.
2. Use json.dumps to serialize the dictionary, and encode to make it bytes
3. Write a "BlockWriter" class that:
   1. Maintains a 4096 byte "block_buffer".
   2. Maintains a monotonically incrementing integer record index value which
      gets applied to new records.
   3. Maintains first and last record index values
      (future versions will allow trim of records from front of file, so
      first index will not always be 0)
   4. Accepts a header Record Structure Header, Tralier and a bytes object
   5. Constructs a "sausage" object that references the Record Structure Header
      and the bytes, creates and references a new, incomplete Record Structure
      Tailer and calculates the total bytes required for writing this to disk.
      This is refered to as the "content" size.
   6. Calculates a trial sauasge size of by adding the size of a single slice
      header and tailer to the sausage content size.
   7. Test the remaining space in the block_buffer to see if the full sausage
      can fit
      1. If so, the slice header and footer are created accordingly and the
	 slice header, sausage content and slice footer are written into
	 the block buffer.
      2. If not, then the sausage is sliced so that the first slice will
	 fit in the block_buffer and the remaining sausage is left whole.
	 The first slice is written into the block buffer
   8. After the buffer write the buffer_block remaining space is checked to
      see if it exceeds the total of:
      1. A slice header/trailer pair
      2. A record header/trailer pair
      3. A number of bytes equal to the class property "min_content_size".
   9. If the buffer_block free space is less that this total, it is padded with
      zeros out to 4096 bytes in length, then written to the file. At this
      stage of the progject the file should be an ordinary file opened
      in byte write mode, not a direct IO file.
   10. If any sausage remains, the slice and write process is repeated until
       the entire sausage is consumed. The block_buffer may have part of the
       sauage remaining at this point.
   11. Returns the record index to the caller.
   12. Has a "flush" method that checks to see if the block_buffer has any
       content, and if it does it pads the buffer and writes it out.
   13. Has a close method that calls the "flush" method and then closes the file.
4. Write a "Recorder" class that accepts a bytes object and an integer "record_type_code".
   1. Have it create the Record Structure Header
   2. Have it store the last X records in a list in memory, where X is a class property
      named "cache size".
   3. Have it submit the Record Structure Header to the BlockWriter class and
      receive in return the record index
5. Write a "BlockReader" class that reads files generated by BlockWriter
   1. Builds an catalog of the records with:
      1. Record index
      2. Record type_code
      3. First slice location in block number and offset form.
      4. Last slice location in block number and offset form.
      5. Returns the first and last record index value
   2. Has a "get_record" method that accepts in index and returns the
      reconsituted bytes that were originally saved, along with the record type code



      
   
